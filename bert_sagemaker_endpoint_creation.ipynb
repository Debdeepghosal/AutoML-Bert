{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87fec3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./inference.py\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "target_list=['autos',\n",
    " 'baseball',\n",
    " 'christian',\n",
    " 'comp',\n",
    " 'crypt',\n",
    " 'electronics',\n",
    " 'forsale',\n",
    " 'graphics',\n",
    " 'hardware',\n",
    " 'hockey',\n",
    " 'ibm',\n",
    " 'mac',\n",
    " 'med',\n",
    " 'misc',\n",
    " 'motorcycles',\n",
    " 'ms-windows',\n",
    " 'os',\n",
    " 'pc',\n",
    " 'politics',\n",
    " 'rec',\n",
    " 'religion',\n",
    " 'sci',\n",
    " 'soc',\n",
    " 'space',\n",
    " 'sport',\n",
    " 'sys',\n",
    " 'talk',\n",
    " 'windows',\n",
    " 'x']\n",
    "\n",
    "# Hyperparameters\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "THRESHOLD = 0.5 # threshold for the sigmoid\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "\n",
    "try:\n",
    "    from transformers import BertTokenizer, BertModel\n",
    "except ImportError:\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"transformers\"])\n",
    "    from transformers import BertTokenizer, BertModel\n",
    "    \n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClass, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased', return_dict=True)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.linear = torch.nn.Linear(768, len(target_list))\n",
    "\n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):\n",
    "        output = self.bert_model(\n",
    "            input_ids, \n",
    "            attention_mask=attn_mask, \n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        output_dropout = self.dropout(output.pooler_output)\n",
    "        output = self.linear(output_dropout)\n",
    "        return output\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    logger.info(\"Loading model...\")\n",
    "    model = BERTClass()\n",
    "    \n",
    "    with open(os.path.join(model_dir , 'model.pth'), 'rb') as f:\n",
    "        model.load_state_dict(torch.load(f,map_location=torch.device(device)))\n",
    "    \n",
    "\n",
    "    model = model.to(device).eval()\n",
    "    \n",
    "    logger.info(\"Model loaded.\")\n",
    "    return model\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    assert request_content_type == \"application/json\"\n",
    "    data = json.loads(request_body)[\"inputs\"]\n",
    "    return data\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    logger.info(\"Tokenizing input data...\")\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    encoded_text = tokenizer.encode_plus(\n",
    "    input_data,\n",
    "    max_length=MAX_LEN,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=True,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    "    )\n",
    "     \n",
    "    input_ids = encoded_text['input_ids'].to(device)\n",
    "    attention_mask = encoded_text['attention_mask'].to(device)\n",
    "    token_type_ids = encoded_text['token_type_ids'].to(device)\n",
    "    output = model(input_ids, attention_mask, token_type_ids)\n",
    "     # add sigmoid, for the training sigmoid is in BCEWithLogitsLoss\n",
    "    output = torch.sigmoid(output).detach().cpu()\n",
    "    # thresholding at 0.5\n",
    "    output = output.flatten().round().numpy()\n",
    "\n",
    "    # Correctly identified the topic of the paper: High energy physics\n",
    "#     print(f\"Title: {raw_text}\")\n",
    "    label=''\n",
    "    for idx, p in enumerate(output):\n",
    "        if p==1:\n",
    "    #         print(f\"Label: {target_list[idx]}\")\n",
    "            label=label+' '+target_list[idx]\n",
    "    return label\n",
    "\n",
    "def output_fn(predictions, content_type):\n",
    "    assert content_type == \"application/json\"\n",
    "    return json.dumps(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "645aa722",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir code\n",
    "\n",
    "!cp MLTC_model_state.bin model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d694ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp inference.py code/inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2f7b784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\r\n",
      "./code/\r\n",
      "./code/inference.py\r\n",
      "./model.pth\r\n"
     ]
    }
   ],
   "source": [
    "# !tar -czvf model.tar.gz -C my_model ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0849eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp MLTC_model_state.bin model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "037318ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pth\n",
      "code/\n",
      "code/inference.py\n"
     ]
    }
   ],
   "source": [
    "!tar -czvf model.tar.gz model.pth code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69ee80d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./model.tar.gz to s3://bert-2/model/model.tar.gz            \n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp model.tar.gz s3://bert-2/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f1d7f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker import get_execution_role, Session\n",
    "\n",
    "sess = Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "model = PyTorchModel(\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"code\",\n",
    "    role=role,\n",
    "    model_data='s3://bert-2/model/model.tar.gz',\n",
    "    framework_version=\"2.1.0\",\n",
    "    py_version=\"py310\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d21fdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# set local_mode to False if you want to deploy on a remote\n",
    "# SageMaker instance\n",
    "\n",
    "local_mode = False\n",
    "\n",
    "if local_mode:\n",
    "    instance_type = \"local\"\n",
    "else:\n",
    "    instance_type = \"ml.m5.large\"\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    serializer=JSONSerializer(),\n",
    "    deserializer=JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "edb5f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"inputs\": '''From: astein@nysernet.org (Alan Stein)\n",
    "Subject: Re: Pease without justice cann't last Re: Last Opportunity for Peace\n",
    "Organization: NYSERNet, Inc.\n",
    "Lines: 18\n",
    "\n",
    "It seems that, to keep the peace talks going, Israel has to keep\n",
    "making goodwill gesture after goodwill gesture, while Palestinian\n",
    "Arabs continue to go around hunting Jews.\n",
    "\n",
    "If the peace talks are going to have any realistic chance of success,\n",
    "the Arabs are going to have to start reciprocating, especially since\n",
    "they are the ones who will be getting tangible concessions in return\n",
    "for giving up only intangibles.  If they keep trying to change the\n",
    "already agreed upon rules, which seems to be one of their favorite\n",
    "games, the Israelis are not likely to be very confident that the\n",
    "intangibles they will receive at the bargaining table will be worth\n",
    "the parchment they're written on.\n",
    "\n",
    "It takes two to negotiate a peace.  It's time for the Arabs to start\n",
    "doing their share.\n",
    "\n",
    "-- \n",
    "Alan H. Stein                     astein@israel.nysernet.org\n",
    "\n",
    "        '''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e78cc232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " politics talk\n"
     ]
    }
   ],
   "source": [
    "res = predictor.predict(data)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fff98741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af193cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
